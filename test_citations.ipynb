{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just Using GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import textwrap\n",
    "\n",
    "openai.api_key  = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   \"books\": [     {       \"book_id\": 1,       \"title\": \"The Enigma of Elysium\",       \"author\": \"Evelyn Sinclair\",       \"genre\": \"Mystery\"\n",
      "},     {       \"book_id\": 2,       \"title\": \"Whispers in the Wind\",       \"author\": \"Nathaniel Blackwood\",       \"genre\": \"Fantasy\"     },\n",
      "{       \"book_id\": 3,       \"title\": \"Echoes of the Past\",       \"author\": \"Amelia Hart\",       \"genre\": \"Romance\"     }   ] }\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along \\ \n",
    "with their authors and genres. \n",
    "Provide them in JSON format with the following keys: \n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(textwrap.fill(response, width=140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"papers\": [\n",
      "    {\n",
      "      \"title\": \"On the Electrodynamics of Moving Bodies\",\n",
      "      \"author\": \"Albert Einstein\",\n",
      "      \"publication\": \"Annalen der Physik\",\n",
      "      \"pub_year\": 1905\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The Structure of DNA\",\n",
      "      \"author\": \"James Watson, Francis Crick\",\n",
      "      \"publication\": \"Nature\",\n",
      "      \"pub_year\": 1953\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A Brief History of Time\",\n",
      "      \"author\": \"Stephen Hawking\",\n",
      "      \"publication\": \"Bantam Books\",\n",
      "      \"pub_year\": 1988\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The Origin of Species\",\n",
      "      \"author\": \"Charles Darwin\",\n",
      "      \"publication\": \"John Murray\",\n",
      "      \"pub_year\": 1859\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The Theory of General Relativity\",\n",
      "      \"author\": \"Albert Einstein\",\n",
      "      \"publication\": \"Annalen der Physik\",\n",
      "      \"pub_year\": 1915\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of five important scientific papers along \\ \n",
    "with their authors, publication (journal/conference/etc.) and year of publication. \n",
    "Provide them in JSON format with the following keys: \n",
    "title, author, publication and pub_year.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Transition-Aware Human Activity Recognition Using Smartphones\",\n",
      "  \"author\": \"Yanqing Zhang, Ling Chen, and Jun Luo\",\n",
      "  \"publication\": \"IEEE Transactions on Mobile Computing\",\n",
      "  \"pub_year\": \"2018\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"title\": \"Deep Convolutional Neural Networks for Human Activity Recognition Using Mobile Sensors\",\n",
      "  \"author\": \"Daniele Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, and Jorge L. Reyes-Ortiz\",\n",
      "  \"publication\": \"Neural Networks\",\n",
      "  \"pub_year\": \"2013\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"title\": \"A Survey on Human Activity Recognition Using Wearable Sensors\",\n",
      "  \"author\": \"Niloofar Hezarjaribi, Hamidreza Memarzadeh-Tehran, and Diane J. Cook\",\n",
      "  \"publication\": \"IEEE Communications Surveys & Tutorials\",\n",
      "  \"pub_year\": \"2018\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"title\": \"Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine\",\n",
      "  \"author\": \"Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, and Jorge L. Reyes-Ortiz\",\n",
      "  \"publication\": \"International Workshop of Ambient Assisted Living\",\n",
      "  \"pub_year\": \"2012\"\n",
      "}\n",
      "\n",
      "{\n",
      "  \"title\": \"Activity Recognition from Accelerometer Data on a Personal Mobile Device\",\n",
      "  \"author\": \"Jennifer R. Kwapisz, Gary M. Weiss, and Samuel A. Moore\",\n",
      "  \"publication\": \"ACM SIGKDD Workshop on Mining Data Semantics\",\n",
      "  \"pub_year\": \"2010\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of five influential scientific papers related to the paper with the title delimited by ''' along with their \n",
    "authors, publication (journal/conference/etc.), and year of publication. Provide the information in JSON format with the following keys: \n",
    "title, author, publication, and pub_year. The paper in question has the title: \n",
    "'''Transition-Aware Human Activity Recognition Using Smartphones'''.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"knowledge_cut_off\": \"My knowledge is limited to scientific papers published up until 2021.\",\n",
      "  \"potential_shortcomings\": \"I may not have access to the most recent or obscure scientific papers.\",\n",
      "  \"papers\": [\n",
      "    {\n",
      "      \"author\": \"Kwapisz, Jennifer R. and Weiss, Gary M. and Moore, Susan A.\",\n",
      "      \"publication\": \"Journal of Biomedical and Health Informatics\",\n",
      "      \"pub_year\": \"2011\"\n",
      "    },\n",
      "    {\n",
      "      \"author\": \"Anguita, Davide and Ghio, Alessandro and Oneto, Luca and Parra, Xavier\",\n",
      "      \"publication\": \"Journal of Ambient Intelligence and Humanized Computing\",\n",
      "      \"pub_year\": \"2013\"\n",
      "    },\n",
      "    {\n",
      "      \"author\": \"Bulling, Andreas and Blanke, Ulf and Schiele, Bernt\",\n",
      "      \"publication\": \"Pervasive and Mobile Computing\",\n",
      "      \"pub_year\": \"2014\"\n",
      "    },\n",
      "    {\n",
      "      \"author\": \"Ravi, Daniele and Wong, Chi-Wing and Lo, Benny and Yang, Zhigang\",\n",
      "      \"publication\": \"Pattern Recognition\",\n",
      "      \"pub_year\": \"2016\"\n",
      "    },\n",
      "    {\n",
      "      \"author\": \"Ordóñez, Francisco J. and Roggen, Daniel\",\n",
      "      \"publication\": \"Pattern Recognition Letters\",\n",
      "      \"pub_year\": \"2016\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of five influential scientific papers related to the paper with the title delimited by ''' along with their \n",
    "authors, publication (journal/conference/etc.), and year of publication. Provide the information in JSON format with the following keys: \n",
    "author, publication, and pub_year. The paper in question has the title: \n",
    "'''Transition-Aware Human Activity Recognition Using Smartphones'''.\n",
    "Additionally I want you to provide the reader of this list with very concise information about your limited knowledge and potential \n",
    "shortcomings (e.g. your knowledge cut off) at the beginning of your answer.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My knowledge is limited to the information I have been trained on, which includes a wide range of general knowledge topics. However, I do not have access to real-time information or the ability to browse the internet. Therefore, I may not have the most up-to-date information on specific scientific papers. Additionally, my training data only goes up until 2021, so I may not have information on scientific papers published after that year.\n",
      "\n",
      "Here is a list of five influential scientific papers related to the paper titled \"Transition-Aware Human Activity Recognition Using Smartphones\":\n",
      "\n",
      "1. Paper: \"Deep Convolutional Neural Networks for Human Activity Recognition Using Mobile Sensors\"\n",
      "   Authors: Yong Du, Wei Wang, and Liang Wang\n",
      "   Publication: ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp)\n",
      "   Year: 2015\n",
      "\n",
      "2. Paper: \"A Survey on Human Activity Recognition Using Wearable Sensors\"\n",
      "   Authors: Nur Al Hasan Haldar, Md. Kamrul Hasan, and Md. Rashedul Islam\n",
      "   Publication: IEEE Access\n",
      "   Year: 2019\n",
      "\n",
      "3. Paper: \"Human Activity Recognition Using Smartphones with Deep Learning Models\"\n",
      "   Authors: Zhenyu Wang, Zhiwen Yu, and Yunhong Wang\n",
      "   Publication: IEEE Access\n",
      "   Year: 2018\n",
      "\n",
      "4. Paper: \"A Comparative Study of Human Activity Recognition Using Smartphone Accelerometers\"\n",
      "   Authors: Sebastian Dernbach, David V. Lu, and Antonio Krüger\n",
      "   Publication: ACM Conference on Ubiquitous Computing (UbiComp)\n",
      "   Year: 2012\n",
      "\n",
      "5. Paper: \"Activity Recognition on Smartphones via Sensor-Fusion and Deep Learning\"\n",
      "   Authors: Linglong Kong, Philip H. S. Torr, and Roberto Cipolla\n",
      "   Publication: IEEE International Conference on Computer Vision (ICCV)\n",
      "   Year: 2015\n",
      "\n",
      "JSON format:\n",
      "```\n",
      "{\n",
      "  \"papers\": [\n",
      "    {\n",
      "      \"author\": \"Yong Du, Wei Wang, Liang Wang\",\n",
      "      \"publication\": \"ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp)\",\n",
      "      \"pub_year\": 2015\n",
      "    },\n",
      "    {\n",
      "      \"author\": \"Nur Al Hasan Haldar, Md. Kamrul Hasan, Md. Rashedul Islam\",\n",
      "      \"publication\": \"IEEE Access\",\n",
      "      \"pub_year\": 2019\n",
      "    },\n",
      "    {\n",
      "      \"author\": \"Zhenyu Wang, Zhiwen Yu, Yunhong Wang\",\n",
      "      \"publication\": \"IEEE Access\",\n",
      "      \"pub_year\": 2018\n",
      "    },\n",
      "    {\n",
      "      \"author\": \"Sebastian Dernbach, David V. Lu, Antonio Krüger\",\n",
      "      \"publication\": \"ACM Conference on Ubiquitous Computing (UbiComp)\",\n",
      "      \"pub_year\": 2012\n",
      "    },\n",
      "    {\n",
      "      \"author\": \"Linglong Kong, Philip H. S. Torr, Roberto Cipolla\",\n",
      "      \"publication\": \"IEEE International Conference on Computer Vision (ICCV)\",\n",
      "      \"pub_year\": 2015\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of five influential scientific papers related to the paper with the title delimited by ''' along with their \n",
    "authors, publication (journal/conference/etc.), and year of publication. Provide the information in JSON format with the following keys: \n",
    "author, publication, and pub_year. The paper in question has the title: \n",
    "'''Transition-Aware Human Activity Recognition Using Smartphones'''.\n",
    "Additionally I want you to provide the reader of this list with very concise information about you limited knowledge and potential \n",
    "shortcomings (e.g. your knowledge cut off) at the beginning of your answer. This information should just be in the form of text, \n",
    "not in a JSON format.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My knowledge is limited to the information I have been trained on, which includes a wide range of topics but may not cover all scientific papers. I may not have access to the most recent papers or be aware of specific details about certain papers. \n",
      "\n",
      "Here is a list of five influential scientific papers related to the paper \"Transition-Aware Human Activity Recognition Using Smartphones\":\n",
      "\n",
      "1. Paper: \"Deep Convolutional Neural Networks for Human Activity Recognition Using Mobile Sensors\"\n",
      "   Authors: Yong Du, Wenwu Zhu, Ling Shao\n",
      "   Publication: ACM Transactions on Intelligent Systems and Technology\n",
      "   Year: 2015\n",
      "\n",
      "2. Paper: \"A Survey on Human Activity Recognition Using Wearable Sensors\"\n",
      "   Authors: Nwe Ni Tun, Hwee-Pink Tan, Wei Tsang Ooi\n",
      "   Publication: IEEE Communications Surveys & Tutorials\n",
      "   Year: 2014\n",
      "\n",
      "3. Paper: \"Activity Recognition on Smartphones via Sensor-Fusion and Deep Learning\"\n",
      "   Authors: Yu Guan, Jiawei Chen, Guangtao Xue, et al.\n",
      "   Publication: IEEE Transactions on Mobile Computing\n",
      "   Year: 2018\n",
      "\n",
      "4. Paper: \"Human Activity Recognition Using Smartphones with Deep Learning Models\"\n",
      "   Authors: Zhenyu Wang, Wenjie Ruan, Shuai Huang, et al.\n",
      "   Publication: IEEE Access\n",
      "   Year: 2018\n",
      "\n",
      "5. Paper: \"A Comparative Study of Human Activity Recognition Using Smartphone Accelerometers\"\n",
      "   Authors: Sebastian Dernbach, David V. Lu, Michael A. Riegler, et al.\n",
      "   Publication: ACM Multimedia\n",
      "   Year: 2012\n",
      "\n",
      "{\n",
      "  \"1\": {\n",
      "    \"author\": \"Yong Du, Wenwu Zhu, Ling Shao\",\n",
      "    \"publication\": \"ACM Transactions on Intelligent Systems and Technology\",\n",
      "    \"pub_year\": 2015\n",
      "  },\n",
      "  \"2\": {\n",
      "    \"author\": \"Nwe Ni Tun, Hwee-Pink Tan, Wei Tsang Ooi\",\n",
      "    \"publication\": \"IEEE Communications Surveys & Tutorials\",\n",
      "    \"pub_year\": 2014\n",
      "  },\n",
      "  \"3\": {\n",
      "    \"author\": \"Yu Guan, Jiawei Chen, Guangtao Xue, et al.\",\n",
      "    \"publication\": \"IEEE Transactions on Mobile Computing\",\n",
      "    \"pub_year\": 2018\n",
      "  },\n",
      "  \"4\": {\n",
      "    \"author\": \"Zhenyu Wang, Wenjie Ruan, Shuai Huang, et al.\",\n",
      "    \"publication\": \"IEEE Access\",\n",
      "    \"pub_year\": 2018\n",
      "  },\n",
      "  \"5\": {\n",
      "    \"author\": \"Sebastian Dernbach, David V. Lu, Michael A. Riegler, et al.\",\n",
      "    \"publication\": \"ACM Multimedia\",\n",
      "    \"pub_year\": 2012\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of five influential scientific papers related to the paper with the title delimited by ''' along with their \n",
    "authors, publication (journal/conference/etc.), and year of publication. Provide the information about the related papers in JSON format with the following keys: \n",
    "author, publication, and pub_year. The paper in question has the title: \n",
    "'''Transition-Aware Human Activity Recognition Using Smartphones'''.\n",
    "Additionally I want you to provide the reader of this list with concise information about you limited knowledge and potential \n",
    "shortcomings (e.g. your knowledge cut off) at the beginning of your answer. This information should just be in the form of text, \n",
    "not in a JSON format. I want all text to appear in lines of at maximum 150 characters. After that use a linebreak like in python with \"\\n\".\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My knowledge is limited to the information available in the pre-trained models and datasets I have been trained on. I do not have access to real-time information or the ability to browse the internet. Therefore, the list of influential scientific papers related to \"Transition-Aware Human Activity Recognition Using Smartphones\" provided below is based on my pre-existing knowledge and may not include the most recent or comprehensive research in the field.\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"title\": \"A Survey on Human Activity Recognition Using Smartphones\",\n",
      "    \"authors\": \"Alberto Incel, Mehmet Kose, Cem Ersoy\",\n",
      "    \"publication\": \"IEEE Communications Surveys & Tutorials\",\n",
      "    \"year\": \"2013\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition\",\n",
      "    \"authors\": \"Oscar Casas, Petia Radeva\",\n",
      "    \"publication\": \"Sensors\",\n",
      "    \"year\": \"2019\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Human Activity Recognition Using Smartphones with Deep Learning Models\",\n",
      "    \"authors\": \"Zebin Yang, Zhijie Wen, Zhongming Zhao\",\n",
      "    \"publication\": \"Symmetry\",\n",
      "    \"year\": \"2019\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"A Comparative Study on Human Activity Recognition Using Accelerometer Data from Smartphones\",\n",
      "    \"authors\": \"Ignacio Angulo, Diego Pizzocaro, Xavier Baro, Francesc X. Prenafeta-Boldú\",\n",
      "    \"publication\": \"Sensors\",\n",
      "    \"year\": \"2015\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Human Activity Recognition Using Smartphones Based on Deep Learning Recurrent Neural Networks\",\n",
      "    \"authors\": \"Yanwei Pang, Guohui Tian, Chunhua Ju\",\n",
      "    \"publication\": \"Symmetry\",\n",
      "    \"year\": \"2019\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# better formatting\n",
    "prompt = f\"\"\"\n",
    "Generate a JSON list of five influential scientific papers related to the paper with the title delimited by ''' along with their authors, \n",
    "publication (journal/conference/etc.), and year of publication. The paper in question has the title: \n",
    "'''Transition-Aware Human Activity Recognition Using Smartphones'''. Begin your response with a brief statement about your knowledge \n",
    "limitations and potential shortcomings (e.g. your knowledge cut off). This statement should not be in JSON format and should adhere \n",
    "to a maximum character count of 150 per line, using a line break for longer content.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My knowledge is limited to the information available in the pre-trained models and datasets I have been trained on. I do not have access to real-time information or the ability to browse the internet. Therefore, I cannot generate a JSON list of influential scientific papers related to the paper \"Transition-Aware Human Activity Recognition Using Smartphones\" without this specific information.\n"
     ]
    }
   ],
   "source": [
    "# just cahnged five to 5 and it doesn't work anymore (no JSON)\n",
    "prompt = f\"\"\"\n",
    "Generate a JSON list of 5 influential scientific papers related to the paper with the title delimited by ''' along with their authors, \n",
    "publication (journal/conference/etc.), and year of publication. The paper in question has the title: \n",
    "'''Transition-Aware Human Activity Recognition Using Smartphones'''. Begin your response with a brief statement about your knowledge \n",
    "limitations and potential shortcomings (e.g. your knowledge cut off). This statement should not be in JSON format and should adhere \n",
    "to a maximum character count of 150 per line, using a line break for longer content.\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement: Please note that the list of influential scientific papers provided below is based on the training data and knowledge available to me. There may be other equally or more influential papers that are not included in this list. Additionally, the list is limited to papers related to the field of \"Transition-Aware Human Activity Recognition Using Smartphones\" as specified in the given title.\n",
      "\n",
      "{\n",
      "  \"papers\": [\n",
      "    {\n",
      "      \"title\": \"A Survey on Human Activity Recognition Using Wearable Sensors\",\n",
      "      \"author\": \"Nilofer Ahmed, Muhammad Awais Azam, and Muhammad Imran\",\n",
      "      \"publication\": \"Sensors\",\n",
      "      \"pub_year\": 2018\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition\",\n",
      "      \"author\": \"Yi Yang, Wenjie Ruan, and Ming Li\",\n",
      "      \"publication\": \"Sensors\",\n",
      "      \"pub_year\": 2015\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Deep Convolutional Neural Networks for Human Activity Recognition with Smartphone Sensors\",\n",
      "      \"author\": \"Zenglin Xu, Yuanchun Li, and Mingming Fan\",\n",
      "      \"publication\": \"ACM Transactions on Intelligent Systems and Technology\",\n",
      "      \"pub_year\": 2017\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Human Activity Recognition Using Smartphones with Convolutional Neural Networks\",\n",
      "      \"author\": \"Yi Yang, Wenjie Ruan, and Ming Li\",\n",
      "      \"publication\": \"International Journal of Distributed Sensor Networks\",\n",
      "      \"pub_year\": 2016\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A Review on Human Activity Recognition Using Wearable Sensors\",\n",
      "      \"author\": \"Nilofer Ahmed, Muhammad Awais Azam, and Muhammad Imran\",\n",
      "      \"publication\": \"ACM Computing Surveys\",\n",
      "      \"pub_year\": 2018\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks\",\n",
      "      \"author\": \"Zenglin Xu, Yuanchun Li, and Mingming Fan\",\n",
      "      \"publication\": \"IEEE Access\",\n",
      "      \"pub_year\": 2017\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Human Activity Recognition Using Smartphones Based on Deep Learning Neural Networks\",\n",
      "      \"author\": \"Yi Yang, Wenjie Ruan, and Ming Li\",\n",
      "      \"publication\": \"IEEE Access\",\n",
      "      \"pub_year\": 2016\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Human Activity Recognition Using Wearable Sensors and Deep Learning Networks\",\n",
      "      \"author\": \"Zenglin Xu, Yuanchun Li, and Mingming Fan\",\n",
      "      \"publication\": \"IEEE Transactions on Emerging Topics in Computational Intelligence\",\n",
      "      \"pub_year\": 2017\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Human Activity Recognition Using Smartphones with Deep Convolutional Neural Networks\",\n",
      "      \"author\": \"Yi Yang, Wenjie Ruan, and Ming Li\",\n",
      "      \"publication\": \"IEEE Transactions on Mobile Computing\",\n",
      "      \"pub_year\": 2016\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Human Activity Recognition Using Wearable Sensors and Deep Learning Models: A Comprehensive Review\",\n",
      "      \"author\": \"Nilofer Ahmed, Muhammad Awais Azam, and Muhammad Imran\",\n",
      "      \"publication\": \"IEEE Communications Surveys & Tutorials\",\n",
      "      \"pub_year\": 2019\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# provided clear formatting as example\n",
    "prompt = f\"\"\"\n",
    "\"Generate a JSON list of ten influential scientific papers related to the paper with the title delimited by ''' along with their authors, \n",
    "publication (journal/conference/etc.), and year of publication. The desired JSON format should be similar to the following example:\n",
    "\n",
    "{{\n",
    "  \"papers\": [\n",
    "    {{\n",
    "      \"title\": \"On the Electrodynamics of Moving Bodies\",\n",
    "      \"author\": \"Albert Einstein\",\n",
    "      \"publication\": \"Annalen der Physik\",\n",
    "      \"pub_year\": 1905\n",
    "    }},\n",
    "    ...\n",
    "    ]\n",
    "}}\n",
    "\n",
    "The paper in question has the title: '''Transition-Aware Human Activity Recognition Using Smartphones'''.\n",
    "\n",
    "Before providing the list, start with a statement about your limitations and potential shortcomings due to your training data and knowledge cut-off. \n",
    "This statement should be a concise text.\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caution: The following list of influential scientific papers related to the paper titled \"Transition-Aware Human Activity Recognition Using Smartphones\" is generated based on available training data and knowledge up to a certain cut-off point. Please note that there may be limitations and potential shortcomings in the accuracy and completeness of the information provided. Additionally, some of the details about the papers may be incorrect. \n",
      "\n",
      "{\n",
      "  \"papers\": [\n",
      "    {\n",
      "      \"title\": \"A Survey on Human Activity Recognition Using Wearable Sensors\",\n",
      "      \"author\": \"Nweke, Henry Friday and Teh, Ying Wah and Al-Garadi, Mohammed Ali and Alo, Uzoma\",\n",
      "      \"publication\": \"Sensors\",\n",
      "      \"pub_year\": 2016\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition\",\n",
      "      \"author\": \"Ordóñez, Francisco Javier and Roggen, Daniel\",\n",
      "      \"publication\": \"Sensors\",\n",
      "      \"pub_year\": 2016\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Human Activity Recognition on Smartphones with Awareness of Basic Activities and Postural Transitions\",\n",
      "      \"author\": \"Banos, Oresti and Damas, Miguel and Pomares, Hector and Rojas, Ignacio\",\n",
      "      \"publication\": \"Sensors\",\n",
      "      \"pub_year\": 2014\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A Review on Human Activity Recognition Methods\",\n",
      "      \"author\": \"Bulling, Andreas and Blanke, Ulf and Schiele, Bernt\",\n",
      "      \"publication\": \"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\n",
      "      \"pub_year\": 2014\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Activity Recognition on Smartphones via Sensor-Fusion and Deep Learning\",\n",
      "      \"author\": \"Wang, Yuxuan and Chen, Yan and Hao, Shuji and Peng, Bo and Li, Zhiwen\",\n",
      "      \"publication\": \"Sensors\",\n",
      "      \"pub_year\": 2019\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# much more robust prompt. small changes like number of papers, different titles, etc. still produce desired output.\n",
    "prompt = f\"\"\"\n",
    "\"Generate a JSON list of five influential scientific papers related to the paper with the title delimited by ''' along with their authors, \n",
    "publication (journal/conference/etc.), and year of publication. The desired JSON format should be similar to the following example:\n",
    "\n",
    "{{\n",
    "  \"papers\": [\n",
    "    {{\n",
    "      \"title\": \"On the Electrodynamics of Moving Bodies\",\n",
    "      \"author\": \"Albert Einstein\",\n",
    "      \"publication\": \"Annalen der Physik\",\n",
    "      \"pub_year\": 1905\n",
    "    }},\n",
    "    ...\n",
    "    ]\n",
    "}}\n",
    "\n",
    "The paper in question has the title: '''Transition-Aware Human Activity Recognition Using Smartphones'''.\n",
    "\n",
    "Before providing the list, start with a caution statement about your limitations and potential shortcomings due to your training data and knowledge cut-off. \n",
    "Also mention that some of your information might be incorrect. This statement should be a concise text.\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The papers exist and seem to be related to the given paper. But the authors and publication year are almost always wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caution: As an AI language model, my responses are generated based on a mixture of licensed data, data created by human trainers, and publicly available data. I have not been directly trained on specific scientific papers and do not have real-time access to current research. Therefore, the list of influential scientific papers related to the paper titled \"Transition-Aware Human Activity Recognition Using Smartphones\" provided below is based on general knowledge and may not be exhaustive or up-to-date. Additionally, while I strive to provide accurate and up-to-date information, please note that some of the details and descriptions may be incorrect or outdated. It is always recommended to consult the original papers and reliable sources for authoritative information.\n",
      "\n",
      "{\n",
      "  \"papers\": [\n",
      "    {\n",
      "      \"title\": \"Activity Recognition on Smartphones with Awareness of Basic Activities and Postural Transitions\",\n",
      "      \"author\": \"Ignacio Lopez-Moreno, Oscar D. Lara, and Juan A. Castro\",\n",
      "      \"publication\": \"Sensors\",\n",
      "      \"pub_year\": 2014,\n",
      "      \"description\": \"This paper presents a method for human activity recognition on smartphones that incorporates awareness of basic activities and postural transitions. It introduces a novel algorithm that combines accelerometer and gyroscope data to accurately detect and classify activities, including transitions between activities. The paper's contribution lies in improving the accuracy and robustness of activity recognition systems on smartphones, which has implications for various applications such as healthcare monitoring and context-aware services.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition\",\n",
      "      \"author\": \"Yao Guo, Yan Liu, and Chunhua Shen\",\n",
      "      \"publication\": \"Sensors\",\n",
      "      \"pub_year\": 2018,\n",
      "      \"description\": \"This paper proposes a deep learning approach for multimodal wearable activity recognition using deep convolutional neural networks (CNNs) and long short-term memory (LSTM) recurrent neural networks. By combining data from multiple sensors, including accelerometers and gyroscopes, the proposed model achieves high accuracy in recognizing various human activities. The paper's relevance lies in advancing the field of activity recognition by leveraging deep learning techniques and multimodal sensor data, which has implications for applications such as fitness tracking and human-computer interaction.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A Survey on Human Activity Recognition Using Wearable Sensors\",\n",
      "      \"author\": \"Nwe Nwe Htay, Yeong Min Jang, and Eui-Nam Huh\",\n",
      "      \"publication\": \"International Journal of Distributed Sensor Networks\",\n",
      "      \"pub_year\": 2015,\n",
      "      \"description\": \"This survey paper provides an overview of human activity recognition using wearable sensors. It discusses various aspects of activity recognition systems, including sensor types, feature extraction methods, and classification algorithms. The paper summarizes the state-of-the-art techniques and challenges in the field, highlighting the importance of wearable sensors in enabling accurate and unobtrusive activity recognition. It serves as a valuable resource for researchers and practitioners working on activity recognition using smartphones and other wearable devices.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A Review on Human Activity Recognition Using Wearable Sensors\",\n",
      "      \"author\": \"Seng Loke and Yun Yang\",\n",
      "      \"publication\": \"IEEE Internet of Things Journal\",\n",
      "      \"pub_year\": 2015,\n",
      "      \"description\": \"This review paper provides a comprehensive analysis of human activity recognition using wearable sensors. It surveys the existing literature, discussing various wearable sensor technologies, data collection and preprocessing techniques, and activity recognition algorithms. The paper also highlights the challenges and future directions in the field, emphasizing the potential of wearable sensors for enabling personalized healthcare, assisted living, and activity monitoring. It serves as a valuable reference for researchers and practitioners interested in the field of human activity recognition.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A Survey on Human Activity Recognition Using Wearable Sensors\",\n",
      "      \"author\": \"M. R. Yuce\",\n",
      "      \"publication\": \"IEEE Sensors Journal\",\n",
      "      \"pub_year\": 2013,\n",
      "      \"description\": \"This survey paper provides an overview of human activity recognition using wearable sensors. It discusses the challenges and opportunities in designing activity recognition systems, including sensor selection, feature extraction, and classification techniques. The paper also presents a taxonomy of activity recognition systems and provides insights into the future directions of the field. It serves as a valuable resource for researchers and practitioners working on activity recognition using smartphones and other wearable devices.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# now also with description\n",
    "prompt = f\"\"\"\n",
    "\"Generate a JSON list of five influential scientific papers related to the paper with the title delimited by ''' along with their authors, \n",
    "publication (journal/conference/etc.), year of publication and a short description of why the paper is relevant. The desired JSON format should be similar to the following example:\n",
    "\n",
    "{{\n",
    "  \"papers\": [\n",
    "    {{\n",
    "      \"title\": \"On the Electrodynamics of Moving Bodies\",\n",
    "      \"author\": \"Albert Einstein\",\n",
    "      \"publication\": \"Annalen der Physik\",\n",
    "      \"pub_year\": 1905,\n",
    "      \"description\": \"\"On the Electrodynamics of Moving Bodies\" is a seminal paper by Albert Einstein that introduced the \n",
    "      special theory of relativity, revolutionizing our understanding of space, time, and motion. It challenges conventional \n",
    "      notions by demonstrating that the laws of physics remain consistent for all observers in inertial frames of reference. \n",
    "      This paper's significance lies in its foundational role in modern physics and its relevance to a wide range of scientific disciplines.\"\n",
    "    }},\n",
    "    ...\n",
    "    ]\n",
    "}}\n",
    "\n",
    "The paper in question has the title: '''Transition-Aware Human Activity Recognition Using Smartphones'''.\n",
    "\n",
    "Before providing the list, start with a caution statement about your limitations and potential shortcomings due to your training data and knowledge cut-off. \n",
    "Also mention that some of your information might be incorrect. This statement should be a concise text.\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = f\"\"\"\n",
    "# Act as a prompt engineer. I will give you a prompt delimited by <> and you will improve the prompt for me. Prompt:\n",
    "# <Generate a list of five influential scientific papers related to the paper with the title delimited by ''' along with their \n",
    "# authors, publication (journal/conference/etc.), and year of publication. Provide the information in JSON format with the following keys: \n",
    "# author, publication, and pub_year. The paper in question has the title: \n",
    "# ''' '''.\n",
    "# Additionally I want you to provide the reader of this list with concise information about you limited knowledge and potential \n",
    "# shortcomings (e.g. your knowledge cut off) at the beginning of your answer. This information should just be in the form of text, \n",
    "# not in a JSON format. I want all text to appear in lines of at maximum 150 characters. After that use a linebreak like in python with \"\\n\".>\n",
    "# \"\"\"\n",
    "# response = get_completion(prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scholarly\n",
      "  Using cached scholarly-1.7.11-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: arrow in /home/sisso/.local/lib/python3.10/site-packages (from scholarly) (1.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/sisso/.local/lib/python3.10/site-packages (from scholarly) (4.12.2)\n",
      "Collecting bibtexparser (from scholarly)\n",
      "  Using cached bibtexparser-1.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from scholarly) (1.2.13)\n",
      "Collecting fake-useragent (from scholarly)\n",
      "  Using cached fake_useragent-1.1.3-py3-none-any.whl (50 kB)\n",
      "Collecting free-proxy (from scholarly)\n",
      "  Using cached free_proxy-1.1.1-py3-none-any.whl\n",
      "Requirement already satisfied: httpx in /home/sisso/.local/lib/python3.10/site-packages (from scholarly) (0.24.1)\n",
      "Collecting python-dotenv (from scholarly)\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests[socks] in /home/sisso/.local/lib/python3.10/site-packages (from scholarly) (2.30.0)\n",
      "Collecting selenium (from scholarly)\n",
      "  Using cached selenium-4.10.0-py3-none-any.whl (6.7 MB)\n",
      "Collecting sphinx-rtd-theme (from scholarly)\n",
      "  Using cached sphinx_rtd_theme-1.2.2-py2.py3-none-any.whl (2.8 MB)\n",
      "Requirement already satisfied: typing-extensions in /home/sisso/.local/lib/python3.10/site-packages (from scholarly) (4.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages/python_dateutil-2.8.2-py3.10.egg (from arrow->scholarly) (2.8.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/sisso/.local/lib/python3.10/site-packages (from beautifulsoup4->scholarly) (2.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.10/dist-packages/pyparsing-3.1.0b1-py3.10.egg (from bibtexparser->scholarly) (3.1.0b1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->scholarly) (1.14.1)\n",
      "Requirement already satisfied: lxml in /home/sisso/.local/lib/python3.10/site-packages (from free-proxy->scholarly) (4.9.2)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx->scholarly) (2020.6.20)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/sisso/.local/lib/python3.10/site-packages (from httpx->scholarly) (0.17.2)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx->scholarly) (3.3)\n",
      "Requirement already satisfied: sniffio in /home/sisso/.local/lib/python3.10/site-packages (from httpx->scholarly) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sisso/.local/lib/python3.10/site-packages (from requests[socks]->scholarly) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests[socks]->scholarly) (1.26.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/sisso/.local/lib/python3.10/site-packages (from requests[socks]->scholarly) (1.7.1)\n",
      "Collecting trio~=0.17 (from selenium->scholarly)\n",
      "  Using cached trio-0.22.2-py3-none-any.whl (400 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium->scholarly)\n",
      "  Using cached trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
      "Collecting certifi (from httpx->scholarly)\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sphinx<7,>=1.6 (from sphinx-rtd-theme->scholarly)\n",
      "  Using cached sphinx-6.2.1-py3-none-any.whl (3.0 MB)\n",
      "Collecting docutils<0.19 (from sphinx-rtd-theme->scholarly)\n",
      "  Using cached docutils-0.18.1-py2.py3-none-any.whl (570 kB)\n",
      "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->scholarly)\n",
      "  Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/sisso/.local/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->scholarly) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/sisso/.local/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->scholarly) (3.6.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.0->arrow->scholarly) (1.16.0)\n",
      "Collecting sphinxcontrib-applehelp (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly)\n",
      "  Using cached sphinxcontrib_applehelp-1.0.4-py3-none-any.whl (120 kB)\n",
      "Collecting sphinxcontrib-devhelp (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly)\n",
      "  Using cached sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
      "Collecting sphinxcontrib-jsmath (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly)\n",
      "  Using cached sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly)\n",
      "  Using cached sphinxcontrib_htmlhelp-2.0.1-py3-none-any.whl (99 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.5 (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly)\n",
      "  Using cached sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
      "Collecting sphinxcontrib-qthelp (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly)\n",
      "  Using cached sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.13 in /home/sisso/.local/lib/python3.10/site-packages (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly) (2.15.1)\n",
      "Collecting snowballstemmer>=2.0 (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly)\n",
      "  Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: babel>=2.9 in /home/sisso/.local/lib/python3.10/site-packages (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly) (2.12.1)\n",
      "Collecting alabaster<0.8,>=0.7 (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly)\n",
      "  Using cached alabaster-0.7.13-py3-none-any.whl (13 kB)\n",
      "Collecting imagesize>=1.3 (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly)\n",
      "  Using cached imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx-rtd-theme->scholarly) (21.3)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /home/sisso/.local/lib/python3.10/site-packages (from trio~=0.17->selenium->scholarly) (23.1.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium->scholarly)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium->scholarly)\n",
      "  Using cached outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly) (1.1.2)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium->scholarly)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from Jinja2>=3.0->sphinx<7,>=1.6->sphinx-rtd-theme->scholarly) (2.0.1)\n",
      "Installing collected packages: sortedcontainers, snowballstemmer, fake-useragent, wsproto, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, python-dotenv, outcome, imagesize, docutils, certifi, bibtexparser, alabaster, trio, trio-websocket, sphinx, free-proxy, sphinxcontrib-jquery, selenium, sphinx-rtd-theme, scholarly\n",
      "\u001b[33m  WARNING: The script dotenv is installed in '/home/sisso/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts sphinx-apidoc, sphinx-autogen, sphinx-build and sphinx-quickstart are installed in '/home/sisso/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed alabaster-0.7.13 bibtexparser-1.4.0 certifi-2023.7.22 docutils-0.18.1 fake-useragent-1.1.3 free-proxy-1.1.1 imagesize-1.4.1 outcome-1.2.0 python-dotenv-1.0.0 scholarly-1.7.11 selenium-4.10.0 snowballstemmer-2.2.0 sortedcontainers-2.4.0 sphinx-6.2.1 sphinx-rtd-theme-1.2.2 sphinxcontrib-applehelp-1.0.4 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.1 sphinxcontrib-jquery-4.1 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 trio-0.22.2 trio-websocket-0.10.3 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pybliometrics\n",
      "  Using cached pybliometrics-3.5.2-py2.py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: requests in /home/sisso/.local/lib/python3.10/site-packages (from pybliometrics) (2.30.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages/tqdm-4.65.0-py3.10.egg (from pybliometrics) (4.65.0)\n",
      "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from pybliometrics) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sisso/.local/lib/python3.10/site-packages (from requests->pybliometrics) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->pybliometrics) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sisso/.local/lib/python3.10/site-packages (from requests->pybliometrics) (2023.7.22)\n",
      "Installing collected packages: pybliometrics\n",
      "Successfully installed pybliometrics-3.5.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scholarly\n",
    "!pip install pybliometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly\n",
    "from pybliometrics.scopus import AbstractRetrieval\n",
    "import requests\n",
    "from urllib import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the papers that cited this publication. In the case of a dataset this should mainly be papers that use the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sisso/.local/lib/python3.10/site-packages/scholarly/_scholarly.py:312: DeprecationWarning: invalid escape sequence '\\d'\n",
      "  m = re.search(\"cites=[\\d+,]*\", object[\"citedby_url\"])\n"
     ]
    },
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get publication object from title \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pub \u001b[38;5;241m=\u001b[39m \u001b[43mscholarly\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_single_pub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTransition-Aware Human Activity Recognition Using Smartphones\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Which papers cited that publication?\u001b[39;00m\n\u001b[1;32m      4\u001b[0m citations \u001b[38;5;241m=\u001b[39m [{ \n\u001b[1;32m      5\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: citation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[1;32m      6\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m: citation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[1;32m      7\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m: citation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpub_year\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m               } \n\u001b[1;32m      9\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m citation \u001b[38;5;129;01min\u001b[39;00m scholarly\u001b[38;5;241m.\u001b[39mcitedby(pub)]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scholarly/_scholarly.py:182\u001b[0m, in \u001b[0;36m_Scholarly.search_single_pub\u001b[0;34m(self, pub_title, filled)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Search by scholar query and return a single Publication container object\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m:param pub_title: Title of the publication to search\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m:type filled: bool\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m url \u001b[38;5;241m=\u001b[39m _PUBSEARCH\u001b[38;5;241m.\u001b[39mformat(requests\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mquote(pub_title))\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__nav\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_publication\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scholarly/_navigator.py:281\u001b[0m, in \u001b[0;36mNavigator.search_publication\u001b[0;34m(self, url, filled)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_publication\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    271\u001b[0m                        filled: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PublicationParser:\n\u001b[1;32m    272\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search by scholar query and return a single Publication object\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    :param url: the url to be searched at\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    :rtype: {Publication}\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     publication_parser \u001b[38;5;241m=\u001b[39m PublicationParser(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    283\u001b[0m     pub \u001b[38;5;241m=\u001b[39m publication_parser\u001b[38;5;241m.\u001b[39mget_publication(soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs_or\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m], PublicationSource\u001b[38;5;241m.\u001b[39mPUBLICATION_SEARCH_SNIPPET)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scholarly/_navigator.py:190\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_page(pagerequest, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTriesExceededException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot Fetch from Google Scholar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMaxTriesExceededException\u001b[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "# get publication object from title \n",
    "pub = scholarly.search_single_pub(\"Transition-Aware Human Activity Recognition Using Smartphones\")\n",
    "# Which papers cited that publication?\n",
    "citations = [{ \n",
    "               'title': citation['bib'].get('title'), \n",
    "               'author': citation['bib'].get('author'), \n",
    "               'year': citation['bib'].get('pub_year')\n",
    "              } \n",
    "              for citation in scholarly.citedby(pub)]\n",
    "citations\n",
    "# 2m 10.5s for 661 citations\n",
    "# 11.5s for 22 citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the papers that were referenced in the dataset paper. These are influential papers for the creation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doi necessary for AbstractRetrieval\n",
    "def get_doi(title):\n",
    "    title = parse.quote(title)\n",
    "    url = f\"https://api.crossref.org/works?query.title={title}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if data['message']['items']:\n",
    "        doi = data['message']['items'][0]['DOI']\n",
    "        return doi\n",
    "    else:\n",
    "        print(\"No results found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "Scopus401Error",
     "evalue": "The requestor is not authorized to access the requested view or fields of the resource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScopus401Error\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# an API Key has to be set in the pybliometrics.cfg file see https://pybliometrics.readthedocs.io/en/stable/access.html\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Key can be created with elsevier account. Mine is f31f4061898df2c42eca4f827c670ef2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m doi \u001b[38;5;241m=\u001b[39m get_doi(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransition-Aware Human Activity Recognition Using Smartphones\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m references \u001b[38;5;241m=\u001b[39m \u001b[43mAbstractRetrieval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFULL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreferences\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pybliometrics/scopus/abstract_retrieval.py:706\u001b[0m, in \u001b[0;36mAbstractRetrieval.__init__\u001b[0;34m(self, identifier, refresh, view, id_type, **kwds)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_view \u001b[38;5;241m=\u001b[39m view\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh \u001b[38;5;241m=\u001b[39m refresh\n\u001b[0;32m--> 706\u001b[0m \u001b[43mRetrieval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midentifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midentifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAbstractRetrieval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabstracts-retrieval-response\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_head \u001b[38;5;241m=\u001b[39m chained_get(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_json, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbibrecord\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m\"\u001b[39m], {})\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pybliometrics/scopus/superclasses/retrieval.py:48\u001b[0m, in \u001b[0;36mRetrieval.__init__\u001b[0;34m(self, identifier, api, id_type, **kwds)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Parse file contents\u001b[39;00m\n\u001b[1;32m     47\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mview\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_view, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds}\n\u001b[0;32m---> 48\u001b[0m \u001b[43mBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pybliometrics/scopus/superclasses/base.py:60\u001b[0m, in \u001b[0;36mBase.__init__\u001b[0;34m(self, params, url, api, download, verbose, *args, **kwds)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_json \u001b[38;5;241m=\u001b[39m loads(fname\u001b[38;5;241m.\u001b[39mread_text())\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     header \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mheaders\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m search_request:\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;66;03m# Get number of results\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pybliometrics/scopus/utils/get_content.py:116\u001b[0m, in \u001b[0;36mget_content\u001b[0;34m(url, api, params, **kwds)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m             reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors[resp\u001b[38;5;241m.\u001b[39mstatus_code](reason)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mScopus401Error\u001b[0m: The requestor is not authorized to access the requested view or fields of the resource"
     ]
    }
   ],
   "source": [
    "# an API Key has to be set in the pybliometrics.cfg file see https://pybliometrics.readthedocs.io/en/stable/access.html\n",
    "# Key can be created with elsevier account. Mine is f31f4061898df2c42eca4f827c670ef2\n",
    "\n",
    "doi = get_doi('Transition-Aware Human Activity Recognition Using Smartphones')\n",
    "references = AbstractRetrieval(doi, view='FULL').references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = [{ \n",
    "        'title': reference.title, \n",
    "        'author': reference.authors, \n",
    "        'year': reference.publicationyear\n",
    "      } \n",
    "      for reference in references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Sensor-based activity recognition',\n",
       "  'author': 'Chen, L.; Hoey, J.; Nugent, C.; Cook, D.; Yu, Z.',\n",
       "  'year': '2012'},\n",
       " {'title': 'Pervasive computing at scale: transforming the state of the art',\n",
       "  'author': 'Cook, D.J.; Das, S.K.',\n",
       "  'year': '2012'},\n",
       " {'title': 'From Smart to Cognitive Phones',\n",
       "  'author': 'Campbell, A.; Choudhury, T.',\n",
       "  'year': '2012'},\n",
       " {'title': 'Life patterns: structure from wearable sensors (Ph.D. thesis)',\n",
       "  'author': 'Clarkson, B.P.',\n",
       "  'year': '2002'},\n",
       " {'title': 'Activity recognition using inertial sensing for healthcare, wellbeing and sports applications: a survey',\n",
       "  'author': 'Avci, A.; Bosch, S.; Marin-Perianu, M.; Marin-Perianu, R.; Havinga, P.',\n",
       "  'year': '2010'},\n",
       " {'title': 'Human activity recognition for video surveillance',\n",
       "  'author': 'Lin, W.; Sun, M.-T.; Poovandran, R.; Zhang, Z.',\n",
       "  'year': '2008'},\n",
       " {'title': 'A survey on human activity recognition using wearable sensors',\n",
       "  'author': 'Lara, O.; Labrador, M.',\n",
       "  'year': '2012'},\n",
       " {'title': 'Machine learning methods for classifying human physical activity from on-body accelerometers',\n",
       "  'author': 'Mannini, A.; Sabatini, A.M.',\n",
       "  'year': '2010'},\n",
       " {'title': 'A survey on vision-based human action recognition',\n",
       "  'author': 'Poppe, R.',\n",
       "  'year': '2010'},\n",
       " {'title': 'Predicting mode of transport from iphone accelerometer data',\n",
       "  'author': 'Nham, B.; Siangliulue, K.; Yeung, S.',\n",
       "  'year': '2008'},\n",
       " {'title': 'Activity recognition in the home using simple and ubiquitous sensors',\n",
       "  'author': 'Tapia, E.; Intille, S.; Larson, K.',\n",
       "  'year': '2004'},\n",
       " {'title': 'Activity recognition from user-annotated acceleration data',\n",
       "  'author': 'Bao, L.; Intille, S.',\n",
       "  'year': '2004'},\n",
       " {'title': 'Human activity analysis: a review',\n",
       "  'author': 'Aggarwal, J.; Ryoo, M.S.',\n",
       "  'year': None},\n",
       " {'title': 'Statistical data mining of streaming motion data for activity and fall recognition in assistive environments',\n",
       "  'author': 'Tasoulis, S.K.; Doukas, N.; Plagianakos, V.P.; Maglogiannis, I.',\n",
       "  'year': '2013'},\n",
       " {'title': 'Egocentric activity monitoring and recovery',\n",
       "  'author': 'Behera, A.; Hogg, D.; Cohn, A.',\n",
       "  'year': '2013'},\n",
       " {'title': 'Privacy versus autonomy: a tradeoff model for smart home monitoring technologies',\n",
       "  'author': 'Townsend, D.; Knoefel, F.; Goubran, R.',\n",
       "  'year': '2011'},\n",
       " {'title': None, 'author': 'Yang, G.-Z.; Yacoub, M.', 'year': '2006'},\n",
       " {'title': 'Classification accuracies of physical activities using smartphone motion sensors',\n",
       "  'author': 'Wu, W.; Dasgupta, S.; Ramirez, E.E.; Peterson, C.; Norman, G.J.',\n",
       "  'year': '2012'},\n",
       " {'title': 'Training computationally efficient smartphone-based human activity recognition models',\n",
       "  'author': 'Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.-L.',\n",
       "  'year': '2013'},\n",
       " {'title': 'Byte the bullet: learning on real-world computing architectures',\n",
       "  'author': 'Ghio, A.; Oneto, L.',\n",
       "  'year': '2014'},\n",
       " {'title': 'A public domain dataset for human activity recognition using smartphones',\n",
       "  'author': 'Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.-L.',\n",
       "  'year': '2013'},\n",
       " {'title': 'Human activity recognition via an accelerometer-enabled-smartphone using kernel discriminant analysis',\n",
       "  'author': 'Khan, A.M.; Lee, Y.-K.; Lee, S.; Kim, T.-S.',\n",
       "  'year': '2010'},\n",
       " {'title': 'Opportunity: towards opportunistic activity and context recognition systems',\n",
       "  'author': 'Roggen, D.; Förster, K.; Calatroni, A.; Holleczek, T.; Fang, Y.; Tröster, G.; Lukowicz, P.; Pirkl, G.; Bannach, D.; Kunze, K.; Ferscha, A.; Holzmann, C.; Riener, A.; Chavarriaga, R.; del Millán, J.R.',\n",
       "  'year': '2009'},\n",
       " {'title': 'Centinela: a human activity recognition system based on acceleration and vital sign data',\n",
       "  'author': 'Lara, O.D.; Pérez, A.J.; Labrador, M.A.; Posada, J.D.',\n",
       "  'year': '2012'},\n",
       " {'title': 'Activity recognition with android phone using mixture-of-experts co-trained with labeled and unlabeled data',\n",
       "  'author': 'Lee, Y.S.; Cho, S.B.',\n",
       "  'year': '2014'},\n",
       " {'title': 'Activity recognition using cell phone accelerometers',\n",
       "  'author': 'Kwapisz, J.R.; Weiss, G.M.; Moore, S.A.',\n",
       "  'year': '2011'},\n",
       " {'title': 'Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine',\n",
       "  'author': 'Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.L.',\n",
       "  'year': '2012'},\n",
       " {'title': 'Activity recognition from accelerometer data on a mobile phone',\n",
       "  'author': 'Brezmes, T.; Gorricho, J.; Cotrina, J.',\n",
       "  'year': '2009'},\n",
       " {'title': 'Online motion recognition using an accelerometer in a mobile device',\n",
       "  'author': 'Fuentes, D.; Gonzalez-Abril, L.; Angulo, C.; Ortega, J.',\n",
       "  'year': '2012'},\n",
       " {'title': 'Online human activity recognition on smart phones',\n",
       "  'author': 'Kose, M.; Incel, O.D.; Ersoy, C.',\n",
       "  'year': '2012'},\n",
       " {'title': 'A tutorial on human activity recognition using body-worn inertial sensors',\n",
       "  'author': 'Bulling, A.; Blanke, U.; Schiele, B.',\n",
       "  'year': '2014'},\n",
       " {'title': 'A triaxial accelerometer-based physical-activity recognition via augmented-signal features and a hierarchical recognizer',\n",
       "  'author': 'Khan, A.M.; Lee, Y.-K.; Lee, S.Y.; Kim, T.-S.',\n",
       "  'year': '2010'},\n",
       " {'title': \"Activity monitoring using a smart phone's accelerometer with hierarchical classification\",\n",
       "  'author': 'Zhang, S.; McCullagh, P.; Nugent, C.; Zheng, H.',\n",
       "  'year': '2010'},\n",
       " {'title': \"Ambulatory monitoring of physical activities in patients with parkinson's disease\",\n",
       "  'author': 'Salarian, A.; Russmann, H.; Vingerhoets, F.J.; Burkhard, P.R.; Aminian, K.',\n",
       "  'year': '2007'},\n",
       " {'title': 'Fielded autonomous posture classification systems: design and realistic evaluation',\n",
       "  'author': 'Rednic, R.; Gaura, E.; Kemp, J.; Brusey, J.',\n",
       "  'year': '2013'},\n",
       " {'title': 'Cosar: hybrid reasoning for context-aware activity recognition',\n",
       "  'author': 'Riboni, D.; Bettini, C.',\n",
       "  'year': '2011'},\n",
       " {'title': 'Introducing a new benchmarked dataset for activity monitoring',\n",
       "  'author': 'Reiss, A.; Stricker, D.',\n",
       "  'year': '2012'},\n",
       " {'title': 'A benchmark dataset to evaluate sensor displacement in activity recognition',\n",
       "  'author': 'Banos, O.; Damas, M.; Pomares, H.; Rojas, I.; Tóth, M.A.; Amft, O.',\n",
       "  'year': '2012'},\n",
       " {'title': 'Implementation of a real-time human movement classifier using a triaxial accelerometer for ambulatory monitoring',\n",
       "  'author': 'Karantonis, D.M.; Narayanan, M.R.; Mathie, M.; Lovell, N.H.; Celler, B.G.',\n",
       "  'year': '2006'},\n",
       " {'title': 'Reducing Multiclass to Binary: A Unifying Approach for Margin Classifiers',\n",
       "  'author': 'Allwein, E.L.; Schapire, R.E.; Singer, Y.',\n",
       "  'year': '2001'},\n",
       " {'title': 'Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic',\n",
       "  'author': 'Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.L.',\n",
       "  'year': '2013'},\n",
       " {'title': \"Improvements to platt's smo algorithm for svm classifier design\",\n",
       "  'author': 'Keerthi, S.S.; Shevade, S.K.; Bhattacharyya, C.; Murthy, K.R.K.',\n",
       "  'year': '2001'},\n",
       " {'title': 'In defense of one-vs-all classification',\n",
       "  'author': 'Rifkin, R.; Klautau, A.',\n",
       "  'year': '2004'},\n",
       " {'title': 'Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods',\n",
       "  'author': 'Platt, J.C.',\n",
       "  'year': '1999'},\n",
       " {'title': 'Recognition of basic activities and postural transitions using smartphones data set',\n",
       "  'author': 'Reyes-Ortiz, J.-L.; Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.',\n",
       "  'year': '2014'},\n",
       " {'title': 'Real-time motion classification for wearable computing applications',\n",
       "  'author': 'DeVaul, R.W.; Dunn, S.',\n",
       "  'year': '2001'},\n",
       " {'title': 'What shall we teach our pants?',\n",
       "  'author': 'Van Laerhoven, K.; Cakmakci, O.',\n",
       "  'year': '2000'},\n",
       " {'title': 'Accelerometry based classification of walking patterns using time-frequency analysis',\n",
       "  'author': 'Lovell, N.; Wang, N.; Ambikairajah, E.; Celler, B.G.',\n",
       "  'year': '2007'},\n",
       " {'title': 'Time series analysis of inertial-body signals for the extraction of dynamic properties from human gait',\n",
       "  'author': 'Sama, A.; Pardo-Ayala, D.E.; Cabestany, J.; Rodríguez-Molinero, A.',\n",
       "  'year': '2010'},\n",
       " {'title': 'Human Activity Recognition and Pattern Discovery',\n",
       "  'author': 'Kim, E.; Helal, S.; Cook, D.',\n",
       "  'year': '2010'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First handle the references (papers cited by dataset paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"most relevant references\": [\n",
      "    {\n",
      "      \"title\": \"Sensor-based activity recognition\",\n",
      "      \"author\": \"Chen, L.; Hoey, J.; Nugent, C.; Cook, D.; Yu, Z.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": \"2012\",\n",
      "      \"description\": \"This paper provides an overview of sensor-based activity recognition, discussing various techniques and algorithms used in this field. It is highly relevant to the current research as it lays the foundation for understanding the principles and challenges of activity recognition using sensors.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Pervasive computing at scale: transforming the state of the art\",\n",
      "      \"author\": \"Cook, D.J.; Das, S.K.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": \"2012\",\n",
      "      \"description\": \"This paper explores the concept of pervasive computing and its potential to transform various domains, including activity recognition. It discusses the challenges and opportunities in scaling up pervasive computing systems, making it relevant to the current research on transition-aware activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"From Smart to Cognitive Phones\",\n",
      "      \"author\": \"Campbell, A.; Choudhury, T.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": \"2012\",\n",
      "      \"description\": \"This paper presents the evolution of smartphones from smart to cognitive phones, highlighting the importance of context-awareness and intelligence in mobile devices. It is relevant to the current research as it emphasizes the need for smartphones to understand and adapt to human activities, particularly during transitions.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Activity recognition using inertial sensing for healthcare, wellbeing and sports applications: a survey\",\n",
      "      \"author\": \"Avci, A.; Bosch, S.; Marin-Perianu, M.; Marin-Perianu, R.; Havinga, P.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": \"2010\",\n",
      "      \"description\": \"This survey paper provides an extensive overview of activity recognition using inertial sensing, focusing on its applications in healthcare, wellbeing, and sports. It is highly relevant to the current research as it discusses the potential of using smartphones' inertial sensors for accurate and context-aware activity recognition.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A survey on human activity recognition using wearable sensors\",\n",
      "      \"author\": \"Lara, O.; Labrador, M.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": \"2012\",\n",
      "      \"description\": \"This survey paper reviews various techniques and algorithms for human activity recognition using wearable sensors. It is relevant to the current research as it provides insights into the state-of-the-art methods and challenges in activity recognition, which can be applied to the development of transition-aware activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Machine learning methods for classifying human physical activity from on-body accelerometers\",\n",
      "      \"author\": \"Mannini, A.; Sabatini, A.M.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": \"2010\",\n",
      "      \"description\": \"This paper focuses on machine learning methods for classifying human physical activity using on-body accelerometers. It is relevant to the current research as it provides valuable insights into the application of machine learning algorithms for activity recognition, which can be utilized in the development of accurate and efficient activity recognition models for smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A survey on vision-based human action recognition\",\n",
      "      \"author\": \"Poppe, R.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": \"2010\",\n",
      "      \"description\": \"This survey paper provides an overview of vision-based human action recognition techniques, discussing various approaches and challenges in this field. Although the current research focuses on smartphone-based activity recognition, this paper is relevant as it offers insights into alternative methods and can inspire future research directions.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Activity recognition in the home using simple and ubiquitous sensors\",\n",
      "      \"author\": \"Tapia, E.; Intille, S.; Larson, K.\",\n",
      "      \"publication\": \"2004\",\n",
      "      \"pub_year\": \"2004\",\n",
      "      \"description\": \"This paper presents a study on activity recognition in the home using simple and ubiquitous sensors. Although it predates the smartphone era, it is relevant to the current research as it explores the use of sensors for context-aware activity recognition, which can be adapted to the development of smartphone-based activity recognition models.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A tutorial on human activity recognition using body-worn inertial sensors\",\n",
      "      \"author\": \"Bulling, A.; Blanke, U.; Schiele, B.\",\n",
      "      \"publication\": \"2014\",\n",
      "      \"pub_year\": \"2014\",\n",
      "      \"description\": \"This tutorial paper provides a comprehensive overview of human activity recognition using body-worn inertial sensors. It covers various aspects of activity recognition, including sensor placement, feature extraction, and classification algorithms. It is highly relevant to the current research as it offers practical guidance and insights into developing accurate and robust activity recognition models for smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A public domain dataset for human activity recognition using smartphones\",\n",
      "      \"author\": \"Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.-L.\",\n",
      "      \"publication\": \"2013\",\n",
      "      \"pub_year\": \"2013\",\n",
      "      \"description\": \"This paper introduces a public domain dataset for human activity recognition using smartphones. It provides a valuable resource for benchmarking and evaluating activity recognition algorithms. It is relevant to the current research as it offers a standardized dataset that can be used to validate the performance of transition-aware activity recognition models developed for smartphones.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "title = 'Transition-Aware Human Activity Recognition Using Smartphones'\n",
    "k = 10\n",
    "prompt = f\"\"\"\n",
    "<Delimited by <> is a list of papers that were used as references in the paper '{title}'. As my research assistant, \n",
    "I would like you to evaluate the significance of each of the provided papers and identify the top {k} most important ones. \n",
    "Additionally, give a description of these papers consisting of at most 100 words, highlighting their relevance as references \n",
    "for the current research.\n",
    "Please provide me with the list of those papers in a JSON format that should follow this example:\n",
    "\n",
    "{{\n",
    "  \"most relevant references\": [\n",
    "    {{\n",
    "      \"title\": \"Example Paper Title\",\n",
    "      \"author\": \"Example Author\",\n",
    "      \"publication\": \"Example\",\n",
    "      \"pub_year\": Example Year,\n",
    "      \"description\": \"example description\"\n",
    "    }},\n",
    "    ...\n",
    "    ]\n",
    "}}.\n",
    "\n",
    "List of references:\n",
    "<{ref}>\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mainly just returns the first papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To do this I want you to first give an 'importance score' between 0 and 100 to each paper listed. Then use the {k} papers with the highest score.\n",
    "      \"importance_score\": example score,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"most relevant references\": [\n",
      "    {\n",
      "      \"title\": \"Sensor-based activity recognition\",\n",
      "      \"author\": \"Chen, L.; Hoey, J.; Nugent, C.; Cook, D.; Yu, Z.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 90,\n",
      "      \"description\": \"This paper provides a comprehensive overview of sensor-based activity recognition, which is highly relevant to the current research on transition-aware human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Pervasive computing at scale: transforming the state of the art\",\n",
      "      \"author\": \"Cook, D.J.; Das, S.K.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 85,\n",
      "      \"description\": \"This paper discusses the advancements in pervasive computing and its impact on transforming the state of the art. It provides valuable insights into the potential of using smartphones for activity recognition.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"From Smart to Cognitive Phones\",\n",
      "      \"author\": \"Campbell, A.; Choudhury, T.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 80,\n",
      "      \"description\": \"This paper explores the evolution of smartphones from smart to cognitive phones, highlighting the importance of context-awareness in human activity recognition. It offers valuable insights for the current research.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Activity recognition using inertial sensing for healthcare, wellbeing and sports applications: a survey\",\n",
      "      \"author\": \"Avci, A.; Bosch, S.; Marin-Perianu, M.; Marin-Perianu, R.; Havinga, P.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": 2010,\n",
      "      \"importance_score\": 75,\n",
      "      \"description\": \"This survey paper provides a comprehensive overview of activity recognition using inertial sensing, focusing on its applications in healthcare, wellbeing, and sports. It is highly relevant to the current research on human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A survey on human activity recognition using wearable sensors\",\n",
      "      \"author\": \"Lara, O.; Labrador, M.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 70,\n",
      "      \"description\": \"This survey paper presents an extensive review of human activity recognition using wearable sensors. It covers various techniques and algorithms, making it a valuable reference for the current research.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Machine learning methods for classifying human physical activity from on-body accelerometers\",\n",
      "      \"author\": \"Mannini, A.; Sabatini, A.M.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": 2010,\n",
      "      \"importance_score\": 65,\n",
      "      \"description\": \"This paper focuses on machine learning methods for classifying human physical activity using on-body accelerometers. It provides insights into the classification algorithms, which are relevant to the current research on smartphone-based activity recognition.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A survey on vision-based human action recognition\",\n",
      "      \"author\": \"Poppe, R.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": 2010,\n",
      "      \"importance_score\": 60,\n",
      "      \"description\": \"This survey paper discusses vision-based human action recognition, which provides a different perspective on activity recognition. It offers valuable insights into the potential of combining vision-based and sensor-based approaches.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Activity recognition in the home using simple and ubiquitous sensors\",\n",
      "      \"author\": \"Tapia, E.; Intille, S.; Larson, K.\",\n",
      "      \"publication\": \"2004\",\n",
      "      \"pub_year\": 2004,\n",
      "      \"importance_score\": 55,\n",
      "      \"description\": \"This paper focuses on activity recognition in the home using simple and ubiquitous sensors. It provides insights into the challenges and techniques for recognizing activities in a home environment, which is relevant to the current research.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A tutorial on human activity recognition using body-worn inertial sensors\",\n",
      "      \"author\": \"Bulling, A.; Blanke, U.; Schiele, B.\",\n",
      "      \"publication\": \"2014\",\n",
      "      \"pub_year\": 2014,\n",
      "      \"importance_score\": 50,\n",
      "      \"description\": \"This tutorial paper provides a comprehensive guide to human activity recognition using body-worn inertial sensors. It covers various aspects, including sensor placement, feature extraction, and classification algorithms, making it a valuable reference for the current research.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A public domain dataset for human activity recognition using smartphones\",\n",
      "      \"author\": \"Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.-L.\",\n",
      "      \"publication\": \"2013\",\n",
      "      \"pub_year\": 2013,\n",
      "      \"importance_score\": 45,\n",
      "      \"description\": \"This paper introduces a public domain dataset for human activity recognition using smartphones. It provides a benchmark for evaluating activity recognition algorithms and serves as a valuable resource for the current research.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# first generate importance score\n",
    "title = 'Transition-Aware Human Activity Recognition Using Smartphones'\n",
    "k = 10\n",
    "prompt = f\"\"\"\n",
    "<Delimited by <> is a list of papers that were used as references in the paper '{title}'. As my research assistant, \n",
    "I would like you to evaluate the significance of each of the provided papers and identify the top {k} most important ones. \n",
    "To do this I want you to first give an 'importance score' between 0 and 100 to each paper listed. Then use the {k} papers with the highest score.\n",
    "Additionally, give a description of these papers consisting of at most 100 words, highlighting their relevance as references for the current research.\n",
    "Please provide me with the list of those papers in a JSON format that should follow this example:\n",
    "\n",
    "{{\n",
    "  \"most relevant references\": [\n",
    "    {{\n",
    "      \"title\": \"Example Paper Title\",\n",
    "      \"author\": \"Example Author\",\n",
    "      \"publication\": \"Example\",\n",
    "      \"pub_year\": Example Year,\n",
    "      \"importance_score\": example score,\n",
    "      \"description\": \"example description\"\n",
    "    }},\n",
    "    ...\n",
    "    ]\n",
    "}}.\n",
    "\n",
    "List of references:\n",
    "<{ref}>\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"most relevant references\": [\n",
      "    {\n",
      "      \"title\": \"Sensor-based activity recognition\",\n",
      "      \"authors\": \"Chen, L.; Hoey, J.; Nugent, C.; Cook, D.; Yu, Z.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"description\": \"This paper provides an overview of sensor-based activity recognition, discussing various techniques and algorithms used in this field. It is highly relevant to the current research as it lays the foundation for understanding the concepts and methodologies used in human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Pervasive computing at scale: transforming the state of the art\",\n",
      "      \"authors\": \"Cook, D.J.; Das, S.K.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"description\": \"This paper explores the advancements in pervasive computing and its impact on various domains, including human activity recognition. It discusses the challenges and opportunities in scaling up pervasive computing systems. It is relevant to the current research as it provides insights into the broader context of human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"From Smart to Cognitive Phones\",\n",
      "      \"authors\": \"Campbell, A.; Choudhury, T.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"description\": \"This paper discusses the evolution of smartphones from smart to cognitive phones, focusing on their potential in enabling context-aware applications such as human activity recognition. It highlights the importance of incorporating contextual information in activity recognition algorithms. It is relevant to the current research as it provides insights into the cognitive capabilities of smartphones for activity recognition.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Activity recognition using inertial sensing for healthcare, wellbeing and sports applications: a survey\",\n",
      "      \"authors\": \"Avci, A.; Bosch, S.; Marin-Perianu, M.; Marin-Perianu, R.; Havinga, P.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": 2010,\n",
      "      \"description\": \"This survey paper provides an overview of activity recognition using inertial sensing for healthcare, wellbeing, and sports applications. It discusses various algorithms and techniques used in this field, highlighting their strengths and limitations. It is relevant to the current research as it provides a comprehensive understanding of the state-of-the-art in activity recognition using inertial sensors.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A survey on human activity recognition using wearable sensors\",\n",
      "      \"authors\": \"Lara, O.; Labrador, M.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"description\": \"This survey paper provides a comprehensive overview of human activity recognition using wearable sensors. It discusses various wearable sensor technologies, data collection, and processing techniques, as well as the challenges and future directions in this field. It is relevant to the current research as it provides insights into the use of wearable sensors for activity recognition.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# just explaining that the sequence is irrelevant\n",
    "title = 'Transition-Aware Human Activity Recognition Using Smartphones'\n",
    "k = 5\n",
    "prompt = f\"\"\"\n",
    "Delimited by <> is a list of papers that were used as references in the paper '{title}'. The sequence of the papers in the provided list \n",
    "does not necessarily indicate their relevance. As my research assistant, I would like you to evaluate the significance of each of the \n",
    "provided papers and identify the top {k} most important ones. Additionally, give a description of these papers consisting of at most 100 words, \n",
    "highlighting their relevance as references for the current research.\n",
    "Please provide me with the list of those papers in a JSON format that should follow this example:\n",
    "\n",
    "{{\n",
    "  \"most relevant references\": [\n",
    "    {{\n",
    "      \"title\": \"Example Paper Title\",\n",
    "      \"authors\": \"Example Authors\",\n",
    "      \"publication\": \"Example\",\n",
    "      \"pub_year\": Example Year,\n",
    "      \"description\": \"example description\"\n",
    "    }},\n",
    "    ...\n",
    "    ]\n",
    "}}.\n",
    "\n",
    "List of references:\n",
    "<{ref}>\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"most relevant references\": [\n",
      "    {\n",
      "      \"title\": \"Sensor-based activity recognition\",\n",
      "      \"authors\": \"Chen, L.; Hoey, J.; Nugent, C.; Cook, D.; Yu, Z.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 9,\n",
      "      \"description\": \"This paper provides a comprehensive overview of sensor-based activity recognition, which is highly relevant to the current research on transition-aware human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Pervasive computing at scale: transforming the state of the art\",\n",
      "      \"authors\": \"Cook, D.J.; Das, S.K.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 8,\n",
      "      \"description\": \"This paper discusses the advancements in pervasive computing and its impact on transforming the state of the art. It provides valuable insights into the potential applications and challenges in the field of human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"From Smart to Cognitive Phones\",\n",
      "      \"authors\": \"Campbell, A.; Choudhury, T.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 8,\n",
      "      \"description\": \"This paper explores the evolution of smartphones from smart to cognitive phones, emphasizing the importance of context-awareness and intelligent sensing. It is highly relevant to the current research on transition-aware human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Activity recognition using inertial sensing for healthcare, wellbeing and sports applications: a survey\",\n",
      "      \"authors\": \"Avci, A.; Bosch, S.; Marin-Perianu, M.; Marin-Perianu, R.; Havinga, P.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": 2010,\n",
      "      \"importance_score\": 7,\n",
      "      \"description\": \"This survey paper provides an overview of activity recognition using inertial sensing for various applications, including healthcare, wellbeing, and sports. It offers valuable insights and techniques that can be applied to the current research on transition-aware human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A survey on human activity recognition using wearable sensors\",\n",
      "      \"authors\": \"Lara, O.; Labrador, M.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 7,\n",
      "      \"description\": \"This survey paper focuses on human activity recognition using wearable sensors, which is highly relevant to the current research on transition-aware human activity recognition using smartphones. It provides a comprehensive overview of techniques and challenges in the field.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "title = 'Transition-Aware Human Activity Recognition Using Smartphones'\n",
    "k = 5\n",
    "prompt = f\"\"\"\n",
    "Delimited by <> is a list of papers that were used as references in the paper '{title}'. The sequence of the papers in the provided list \n",
    "does not necessarily indicate their relevance. As my research assistant, I would like you to evaluate the significance of each of the \n",
    "provided papers and identify the top {k} most important ones. To do this I want you to first give an 'importance score' between 0 and 10 to each paper listed. \n",
    "Then use the {k} papers with the highest score. Additionally, give a description of these papers consisting of at most 100 words, \n",
    "highlighting their relevance as references for the current research.\n",
    "Please provide me with the list of those papers in a JSON format that should follow this example:\n",
    "\n",
    "{{\n",
    "  \"most relevant references\": [\n",
    "    {{\n",
    "      \"title\": \"Example Paper Title\",\n",
    "      \"authors\": \"Example Authors\",\n",
    "      \"publication\": \"Example\",\n",
    "      \"pub_year\": Example Year,\n",
    "      \"importance_score\": example score,\n",
    "      \"description\": \"example description\"\n",
    "    }},\n",
    "    ...\n",
    "    ]\n",
    "}}.\n",
    "\n",
    "List of references:\n",
    "<{ref}>\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"most relevant references\": [\n",
      "    {\n",
      "      \"title\": \"Sensor-based activity recognition\",\n",
      "      \"authors\": \"Chen, L.; Hoey, J.; Nugent, C.; Cook, D.; Yu, Z.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 9,\n",
      "      \"description\": \"This paper provides a comprehensive overview of sensor-based activity recognition, which is highly relevant to the current research on transition-aware human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Pervasive computing at scale: transforming the state of the art\",\n",
      "      \"authors\": \"Cook, D.J.; Das, S.K.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 8,\n",
      "      \"description\": \"This paper discusses the advancements in pervasive computing and its impact on transforming the state of the art. It provides valuable insights into the potential applications and challenges in the field of human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"From Smart to Cognitive Phones\",\n",
      "      \"authors\": \"Campbell, A.; Choudhury, T.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 7,\n",
      "      \"description\": \"This paper explores the evolution of smartphones from smart to cognitive phones, highlighting the importance of context-awareness and intelligent sensing. It offers relevant concepts and ideas for enhancing human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Activity recognition using inertial sensing for healthcare, wellbeing and sports applications: a survey\",\n",
      "      \"authors\": \"Avci, A.; Bosch, S.; Marin-Perianu, M.; Marin-Perianu, R.; Havinga, P.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": 2010,\n",
      "      \"importance_score\": 9,\n",
      "      \"description\": \"This survey paper provides a comprehensive overview of activity recognition using inertial sensing for various applications, including healthcare, wellbeing, and sports. It offers valuable insights and techniques that can be applied to the current research on human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A survey on human activity recognition using wearable sensors\",\n",
      "      \"authors\": \"Lara, O.; Labrador, M.\",\n",
      "      \"publication\": \"2012\",\n",
      "      \"pub_year\": 2012,\n",
      "      \"importance_score\": 9,\n",
      "      \"description\": \"This survey paper focuses on human activity recognition using wearable sensors, which is highly relevant to the current research on human activity recognition using smartphones. It provides a comprehensive overview of techniques and challenges in the field.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Machine learning methods for classifying human physical activity from on-body accelerometers\",\n",
      "      \"authors\": \"Mannini, A.; Sabatini, A.M.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": 2010,\n",
      "      \"importance_score\": 8,\n",
      "      \"description\": \"This paper discusses machine learning methods for classifying human physical activity using on-body accelerometers. It offers valuable insights and techniques that can be applied to the current research on human activity recognition using smartphones.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A survey on vision-based human action recognition\",\n",
      "      \"authors\": \"Poppe, R.\",\n",
      "      \"publication\": \"2010\",\n",
      "      \"pub_year\": 2010,\n",
      "      \"importance_score\": 7,\n",
      "      \"description\": \"This survey paper focuses on vision-based human action recognition, providing insights into techniques and challenges in the field. Although the current research focuses on smartphone-based activity recognition, this paper offers valuable perspectives and ideas.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A survey on human activity analysis\",\n",
      "      \"authors\": \"Aggarwal, J.; Ryoo, M.S.\",\n",
      "      \"publication\": null,\n",
      "      \"pub_year\": null,\n",
      "      \"importance_score\": 6,\n",
      "      \"description\": \"This survey paper provides an overview of human activity analysis, which is relevant to the current research on human activity recognition using smartphones. It offers insights into various techniques and applications in the field.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"A public domain dataset for human activity recognition using smartphones\",\n",
      "      \"authors\": \"Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.-L.\",\n",
      "      \"publication\": \"2013\",\n",
      "      \"pub_year\": 2013,\n",
      "      \"importance_score\": 9,\n",
      "      \"description\": \"This paper introduces a public domain dataset for human activity recognition using smartphones, which is highly relevant to the current research. It provides a valuable resource for evaluating and benchmarking activity recognition algorithms.\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Training computationally efficient smartphone-based human activity recognition models\",\n",
      "      \"authors\": \"Anguita, D.; Ghio, A.; Oneto, L.; Parra, X.; Reyes-Ortiz, J.-L.\",\n",
      "      \"publication\": \"2013\",\n",
      "      \"pub_year\": 2013,\n",
      "      \"importance_score\": 8,\n",
      "      \"description\": \"This paper focuses on training computationally efficient smartphone-based human activity recognition models. It offers techniques and insights that can be applied to the current research on transition-aware human activity recognition using smartphones.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "title = 'Transition-Aware Human Activity Recognition Using Smartphones'\n",
    "k = 10\n",
    "prompt = f\"\"\"\n",
    "Delimited by <> is a list of papers that were used as references in the paper '{title}'. The sequence of the papers in the provided list \n",
    "does not necessarily indicate their relevance. As my research assistant, I would like you to evaluate the significance of each of the \n",
    "provided papers and identify the top {k} most important ones. To do this I want you to first give an 'importance score' between 0 and 10 to each paper listed. \n",
    "Then use the {k} papers with the highest score. Additionally, give a description of these papers consisting of at most 100 words, \n",
    "highlighting their relevance as references for the current research.\n",
    "Please provide me with the list of those papers in a JSON format that should follow this example:\n",
    "\n",
    "{{\n",
    "  \"most relevant references\": [\n",
    "    {{\n",
    "      \"title\": \"Example Paper Title\",\n",
    "      \"authors\": \"Example Authors\",\n",
    "      \"publication\": \"Example\",\n",
    "      \"pub_year\": Example Year,\n",
    "      \"importance_score\": example score,\n",
    "      \"description\": \"example description\"\n",
    "    }},\n",
    "    ...\n",
    "    ]\n",
    "}}.\n",
    "\n",
    "List of references:\n",
    "<{ref}>\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hier teilweise nicht die, die in top 5 sind."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
